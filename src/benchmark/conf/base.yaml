num_clients: 4
clients_per_round: 3
num_epochs: 3
num_rounds: 1000
learning_rate: 0.0001
task: None
federated: True 
batch_size: 16
device: cuda:0
metric_type: centralized

dataset:
  federated: ${federated}
  iid: True
  server_dataset: True
  server_dataset_frac: 0.1
  name: insurance
  num_clients: ${num_clients}
  num_features: None
  num_classes: None
  test_frac: 0.2
  batch_size: ${batch_size}
  device: ${device}
  femnist: ${femnist}

model: 
  _target_: None
  name: mlp
  num_layers: 5 
  hidden_dim: [64, 128, 96, 64, 32]
  input_dim: ${dataset.num_features}
  output_dim: ${dataset.num_classes}
  dropout: True
  dropout_prob: 0.1
  num_epochs: ${num_epochs}
  learning_rate: ${learning_rate}
  batch_size: ${batch_size}
  device: ${device}
  loss_fn: mse
  task: ${task}
  optimizer: adam

fit_config:
  drop_client: false
  epochs : ${num_epochs}
  batch_size: ${batch_size}

client_resources:
  num_cpus: 4
  num_gpus: 1

strategy:
  _target_: src.benchmark.strategy.SaveModelStrategy
  fraction_fit: 1.0 # because we want the number of clients to sample on each roudn to be solely defined by min_fit_clients
  min_fit_clients: ${clients_per_round}
  fraction_evaluate: 1.0
  min_evaluate_clients: ${clients_per_round}
  min_available_clients: ${num_clients}

femnist:
  niid: True
  sample_frac: 0.05
  min_num_samples: 128
  partition: sample
  delete_old_partitions: False